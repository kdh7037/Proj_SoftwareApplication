# -*- coding: utf-8 -*-
"""clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-ngm9EIoKlX1n2xwiVm8xRIJZGnBlPKn
"""


# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/Colab Notebooks'

import pandas as pd

df = pd.read_csv("TSNE36.csv")

#검증을 위해 만든 positive 숙소쌍, negative 숙소쌍을 불러온다
pos_pair =  pd.read_csv('test_pos_pair_cos.csv')
neg_pair = pd.read_csv('test_neg_pair_cos.csv')

import sys
#로그 파일 오픈
method = 'cosine'
clustering_method = 'DBSCAN'
f = open(clustering_method+'_tsne_clustering_log_'+method+'.txt', 'w')

import numpy as np

X = df.to_numpy()

import matplotlib.pyplot as plt

from sklearn.cluster import *

#for문을 돌면서 파라미터를 조정하면서 클러스터링 실험
#MeanShift, OPTICS : 메모리 초과
#kmeans, miniBatchKMeans : 불만족스러운 결과
#DBSCAN, HDBSCAN : 불만족스러운 결과
for i in range(1, 2):
  e = i*0.01
  for j in range(50, 100):
    print(i)
    #model = DBSCAN( eps =0.05, mi#pred = model.fit_predict(X)

    #model = KMeans(n_clusters = 12, init='random', random_state=8)
    #model = MeanShift(cluster_all = False)
    
    #model = MiniBatchKMeans(n_clusters=6)
    #model = OPTICS(min_samples = 100)
    #model = hdbscan.HDBSCAN(min_cluster_size=1500)
    
    n_clusters = 7 #최적의 결과를 내는 파라미터
    threshold = 0.2 #최적의 결과를 내는 파라미터
    model = Birch(n_clusters = n_clusters, threshold = threshold) #최적의 결과를 내는 클러스터링 알고리즘
    pred = model.fit_predict(X)

    #시각화를 위한 데이터프레임 만들기
    r = pd.concat([df, pd.DataFrame(pred)], axis=1)
    r.columns = ['x', 'y', 'pred']


    #print('cluster complete')
  
    #클러스터링 검증
    #옳게 분류된 positive pair의 수, negative pair의 수를 세서
    #정확도를 계산한다.
    total_pairs = 0
    correct_pos_pairs = 0
    correct_neg_pairs = 0

    f.write('**********eps:  {}, min_samples: {}\n'.format(e, j))
    sys.stdout.write('**********eps:  {}, min_samples: {}\n'.format(e, j))

    #클러스터 개수, 아웃라이어 제외한 데이터 개수 출력
    n_cluster = 0
    count = len(pred)
    for k in range(len(pred)):
      if pred[k]>=n_cluster:
        n_cluster = pred[k]
      if pred[k] == -1:
        count = count - 1
 
    f.write('n_cluster :  {}, n_filtered_data : {}\n'.format(n_cluster, count))
    sys.stdout.write('n_cluster :  {}, n_filtered_data : {}\n'.format(n_cluster, count))



    #positive pair 검증 과정 & 로그 출력(파일, stdout 모두 출력)
    for  n in range(0, pos_pair.shape[0], 2):
      total_pairs = total_pairs + 1
      

      if pred[pos_pair.loc[n, 'idx']] == pred[pos_pair.loc[n+1, 'idx']] and pred[pos_pair.loc[n, 'idx']] != -1:
        #두 숙소가 같은 클러스터에 있고, 둘 다 아웃라이어가 아니다 => 옳은 분류
        correct_pos_pairs = correct_pos_pairs + 1
        f.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], pred[pos_pair.loc[n, "idx"]]==pred[pos_pair.loc[n+1, "idx"]]))
        sys.stdout.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], pred[pos_pair.loc[n, "idx"]]==pred[pos_pair.loc[n+1, "idx"]]))
       
      elif pred[pos_pair.loc[n, 'idx']] == pred[pos_pair.loc[n+1, 'idx']] and pred[pos_pair.loc[n, 'idx']] == -1:
        #두 숙소 다 아웃라이어다 => 틀린 분류
        f.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], -1))
        sys.stdout.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], -1))
       
      else :
        #두 숙소가 다른 클러스터에 있다 => 틀린 분류
        f.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], pred[pos_pair.loc[n, "idx"]]==pred[pos_pair.loc[n+1, "idx"]]))
        sys.stdout.write('pos, 1 : {}, 2: {}, ==> {}\n'.format(pred[pos_pair.loc[n, "idx"]],pred[pos_pair.loc[n+1, "idx"]], pred[pos_pair.loc[n, "idx"]]==pred[pos_pair.loc[n+1, "idx"]]))
      

    #negative pair 검증 과정 & 로그 출력
    for n in range(0, neg_pair.shape[0], 2):
      total_pairs = total_pairs + 1
      f.write('neg, 1 : {}, 2: {}, ==> {}\n'.format(pred[neg_pair.loc[n, "idx"]], pred[neg_pair.loc[n+1, "idx"]], pred[neg_pair.loc[n, "idx"]]!=pred[neg_pair.loc[n+1, "idx"]]))
      sys.stdout.write('neg, 1 : {}, 2: {}, ==> {}\n'.format(pred[neg_pair.loc[n, "idx"]], pred[neg_pair.loc[n+1, "idx"]], pred[neg_pair.loc[n, "idx"]]!=pred[neg_pair.loc[n+1, "idx"]]))
      
      #두 숙소가 다른 클러스터에 있다 (아웃라이어여도 괜찮음) => 옳은 분류
      if pred[neg_pair.loc[n, 'idx']] != pred[neg_pair.loc[n+1, 'idx']]:
        correct_neg_pairs = correct_neg_pairs + 1

    #최종 결과 출력( 파라미터, 정확도 등)
    f.write('**************eps: {} , min_samples: {}\n'.format(e, j))
    sys.stdout.write('**************eps: {} , min_samples: {}\n'.format(e, j))

    f.write('accuracy: {}, correct pos: {},correct_neg:  {}\n'.format((correct_pos_pairs + correct_neg_pairs)/total_pairs, correct_pos_pairs, correct_neg_pairs))
    sys.stdout.write('accuracy: {}, correct pos: {},correct_neg:  {}\n'.format((correct_pos_pairs + correct_neg_pairs)/total_pairs, correct_pos_pairs, correct_neg_pairs))

    #시각화, 이미지 저장
    plt.close('all')
    plt.scatter(r['x'], r['y'], c=r['pred'], alpha=0.1, s=0.3)
    fig = plt.gcf()
    fig.savefig('image_'+str(i)+'_'+str(j)+'.jpg')
    #break
#f.close()

labels = pd.DataFrame(pred)

#클러스터 레이블 저장
labels.to_csv('labels.csv')